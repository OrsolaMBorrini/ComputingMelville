<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Computing Melville</title>
        <link rel="icon" type="image/x-icon" href="assets/wave_icon.png" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">

        <!-- Google Fonts -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700&family=Poppins&display=swap" rel="stylesheet">
        <!-- Google Icons -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" />
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,700,1,0" />
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@40,600,1,0" />

        <script>
            function initComparisons() {
              var x, i;
              /*find all elements with an "overlay" class:*/
              x = document.getElementsByClassName("img-comp-overlay");
              for (i = 0; i < x.length; i++) {
                /*once for each "overlay" element:
                pass the "overlay" element as a parameter when executing the compareImages function:*/
                compareImages(x[i]);
              }
              function compareImages(img) {
                var slider, img, clicked = 0, w, h;
                /*get the width and height of the img element*/
                w = img.offsetWidth;
                h = img.offsetHeight;
                /*set the width of the img element to 50%:*/
                img.style.width = (w / 2) + "px";
                /*create slider:*/
                slider = document.createElement("DIV");
                slider.setAttribute("class", "img-comp-slider");
                /*insert slider*/
                img.parentElement.insertBefore(slider, img);
                /*position the slider in the middle:*/
                slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";
                /*execute a function when the mouse button is pressed:*/
                slider.addEventListener("mousedown", slideReady);
                /*and another function when the mouse button is released:*/
                window.addEventListener("mouseup", slideFinish);
                /*or touched (for touch screens:*/
                slider.addEventListener("touchstart", slideReady);
                /*and released (for touch screens:*/
                window.addEventListener("touchend", slideFinish);
                function slideReady(e) {
                  /*prevent any other actions that may occur when moving over the image:*/
                  e.preventDefault();
                  /*the slider is now clicked and ready to move:*/
                  clicked = 1;
                  /*execute a function when the slider is moved:*/
                  window.addEventListener("mousemove", slideMove);
                  window.addEventListener("touchmove", slideMove);
                }
                function slideFinish() {
                  /*the slider is no longer clicked:*/
                  clicked = 0;
                }
                function slideMove(e) {
                  var pos;
                  /*if the slider is no longer clicked, exit this function:*/
                  if (clicked == 0) return false;
                  /*get the cursor's x position:*/
                  pos = getCursorPos(e)
                  /*prevent the slider from being positioned outside the image:*/
                  if (pos < 0) pos = 0;
                  if (pos > w) pos = w;
                  /*execute a function that will resize the overlay image according to the cursor:*/
                  slide(pos);
                }
                function getCursorPos(e) {
                  var a, x = 0;
                  e = (e.changedTouches) ? e.changedTouches[0] : e;
                  /*get the x positions of the image:*/
                  a = img.getBoundingClientRect();
                  /*calculate the cursor's x coordinate, relative to the image:*/
                  x = e.pageX - a.left;
                  /*consider any page scrolling:*/
                  x = x - window.pageXOffset;
                  return x;
                }
                function slide(x) {
                  /*resize the image:*/
                  img.style.width = x + "px";
                  /*position the slider:*/
                  slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";
                }
              }
            }
        </script>

    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
            <div class="container px-4">
                <a class="navbar-brand" href="#page-top">Computing Melville</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#documentation" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Documentation</a>
                            <!-- Here's the magic. Add the .animate and .slideIn classes to your .dropdown-menu and you're all set! -->
                            <div class="dropdown-menu dropdown-menu-end animate slideIn" aria-labelledby="navbarDropdown">
                              <a class="dropdown-item" href="#begDoc">Task Definition</a>
                              <a class="dropdown-item" href="#pilot">Pilot</a>
                              <a class="dropdown-item" href="#campaign">Campaign</a>
                              <a class="dropdown-item" href="#pubUse">Publication and use</a>
                            </div>
                          </li>
                        <li class="nav-item"><a class="nav-link" href="#team">Team</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Header-->
        <div class="header bg-primary bg-gradient text-white" id="header" style="background: linear-gradient(60deg, rgba(50, 30, 131, 0.942) 0%, rgba(0,172,193,0.9) 100%),url('assets/transparent_text.jpg')">
            <div class="container px-4 text-center">
                <h1 class="fw-bolder">Computing Melville</h1>
                <p class="subtitle">An automated HTR campaign on Transkribus</p>
                <a href="#about"><i class="material-symbols-outlined" id="expandbutton">expand_more</i></a>
            </div>
            <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
            viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
                <defs>
                    <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/>
                </defs>
                <g class="parallax">
                    <use xlink:href="#gentle-wave" x="48" y="0" fill="rgba(255,255,255,0.7" />
                    <use xlink:href="#gentle-wave" x="48" y="3" fill="rgba(255,255,255,0.5)" />
                    <use xlink:href="#gentle-wave" x="48" y="5" fill="rgba(255,255,255,0.3)" />
                    <use xlink:href="#gentle-wave" x="48" y="7" fill="#fff" />
                </g>
            </svg>
        </div>

        <!-- About section-->
        <section id="about">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>The project</h2>
                        <p class="lead"><i>Computing Melville</i> is a <b>small-scale annotation campaign</b> on a collection of Herman Melville's manuscripts regarding his last novella, "Billy Budd", left unfinished in 1891, and "Rip Van Winkle's Lilac", an experimental combination of prose and poetry.<br>
                            The campaign has been carried out using <b>Transkribus</b>, a platform for the digitisation, AI-powered text recognition, transcription and searching of historical documents.<br>
                            Our aim is to develop a <b>Machine Learning system</b> able to perform a transcription task on Melville's handwritten documents: the model is trained on a selection of chapters from "Billy Budd" manually annotated by the team, and tested on some of "Rip Van Winkle's Lilac" manuscript's leaves.</p>
                        <p>The project has been developed for the "Semantic Digital Libraries" course of the Master Degree in Digital Humanities and Digital Knowledge of the University of Bologna, under prof. Giovanni Colavizza.</p>
                    </div>
                </div>
            </div>
        </section>

        <img src="assets/melvilleprofile_tp.png" id="hm-profile" class="image fitting relative-hm">
        <img src="assets/vw_L.png" id="v-waves" class="image fitting relative-wvL">
        <img src="assets/vw_R.png" id="v-waves" class="image fitting relative-wvR">

        <!-- Documentation section-->
        <section class="bg-light" id="begDoc">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>The transcription pipeline</h2>
                    </div>
                    <div class="col-lg-8">
                        <h3>Task definition</h3>
                            <p class="minor">In this project's pipeline, the task definition step was fundamental: to perform <b>supervised training</b> on a ML model such as ours, it was crucial to first provide it with an <b>annotated corpus</b> to be used as a training set and a <b>raw corpus</b> for the evaluation phase.</p>
                        <h4>Corpus selection</h4>
                            <p>When selecting our starting corpus, we have decided to <b>reuse the data of the <a href="https://mel.netlify.app/">Melville Electronic Library</a></b>: we have selected <b>16 chapters from "Versions of Billy Budd"</b>, an edition comprising not only the reading text but also MEL's TextLab platform, displaying all manuscript leaves and their diplomatic transcription to be used as our training corpus, while digital images of the <b>"Rip Van Winkle's Lilac"</b> manuscript were adopted as the validation set.
                            </p>
                        <h4>Annotation Model</h4>
                            <p>Due to the complexity in interpreting the text from the manuscripts, given also the amount of data, we have decided to <b>rely on the transcriptions made available</b> by the MEL for the development of our training corpus.<br>
                                However, we have employed <b>specific solutions</b> for the challenges related to the peculiarities of Melville's last novella: the original manuscript showcases many leaves and leaf fragments, clearly suggesting the many revisions put in place by the author and complicating the ML task:
                                <div class="table-responsive-lg">
                                    <table class="table">
                                        <thead>
                                            <tr>
                                                <th scope="col">Issue</th>
                                                <th scope="col">Example</th>
                                                <th scope="col">Solution</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <th scope="row">Mounts</th>
                                                <td><img src="assets/examples/mounts_6-187.jpg" class="table-img" alt="Billy Budd, Ch. 6, pg. 187" title="Click to zoom in!"></td>
                                                <td class="table-txt">When leaves of the manuscript display mounts covering large parts of strikethrough text, we have decided to <b>only consider and transcribe the leaf closer to the final authorial version</b> (that is, the leaf <i>with</i> the mount)</td>
                                            </tr>
                                            <tr>
                                                <th scope="row">Additions</th>
                                                <td><img src="assets/examples/additions_1-17.jpg" class="table-img" alt="Billy Budd, Ch. 1, pg. 17"></td>
                                                <td class="table-txt">As we are more interested in showcasing an "analytic" transcription of Melville's manuscripts, every addition to the text has been <b>left in its original position</b> on the page</td>
                                            </tr>
                                            <tr>
                                                <th scope="row">Numbers</th>
                                                <td><img src="assets/examples/numbers_1-47.jpg" class="table-img" alt="Billy Budd, Ch. 1, pg. 47"></td>
                                                <td class="table-txt">All the numbers present on the pages, both at the top and bottom, have been <b>ignored</b>, as the original source of the image does not state clearly their provenance and we are interested in Melville's handwriting only</td>
                                            </tr>
                                            <tr>
                                                <th scope="row">Breaks</th>
                                                <td><img src="assets/examples/breaks_1-75.jpg" class="table-img" alt="Billy Budd, Ch. 1, pg. 75"></td>
                                                <td class="table-txt">All the section breaks' glyphs between the chapters <b>have not been transcribed</b> to avoid any confusion in the recognition of the characters</td>
                                            <tr>
                                                <th scope="row">Marks</th>
                                                <td><img src="assets/examples/signs_8-243.jpg" class="table-img" alt="Billy Budd, Ch. 8, pg. 243"></td>
                                                <td class="table-txt">Any other mark present on the page but not related to the content of the novella (e.g. circles, pencil smears) has been <b>discarded</b></td>
                                            </tr>
                                        </tbody>
                                    </table>
                                    <p class="text-minor"><span class="material-symbols-outlined icon-align" id="zoom_in">zoom_in</span>Click on the pictures to zoom in!</p>
                                </div>
                            
                        <h4>Annotation Guidelines</h4>
                            <p>We have followed <b><a href="https://readcoop.eu/transkribus/howto/transkribus-transcription-conventions/">Transkribus' Transcription Conventions</a></b>, adapting them to our data when needed.<br>
                            In particular, <b>strikethrough</b> and <b>superscript</b> text passages have proved to be a challenge.</p>
                            <div class="table-responsive-lg"><b>Strikethrough text passages</b>
                                <table class="table">
                                    <thead>
                                        <tr>
                                            <th scope="col">Example</th>
                                            <th scope="col">Solution</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/strikethrough_8-237.jpg" class="table-img" alt="Billy Budd, Ch. 8, pg. 237"></th>
                                            <td class="table-txt">Always to be <b>tagged</b> as <code>strikethrough</code> when appearing <b>inline</b> with the rest of the text line</td>
                                        </tr>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/superstrike_8-243.jpg" class="table-img" alt="Billy Budd, Ch. 8, pg. 243"></th>
                                            <td class="table-txt">When <b>co-occurring</b> with <b>superscript</b>, the latter tag is to be preferred</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                            <br>
                            <div class="table-responsive-lg"><b>Superscript text passages</b>
                                <table class="table">
                                    <thead>
                                        <tr>
                                            <th scope="col">Example</th>
                                            <th scope="col">Solution</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/inlinesuper.jpg" class="table-img" alt="Billy Budd, Ch. 6, pg. 189"></th>
                                            <td class="table-txt">When the <b>x-height</b> of the characters is <b>included</b> in the main line area, <b>tag</b> it as <code>superscript</code></td>
                                        </tr>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/twolines_1-23.jpg" class="table-img" alt="Billy Budd, Ch. 1, pg. 53"></th>
                                            <td class="table-txt">When the <b>x-height</b> of the characters is <b><i>not</i> included</b> in the main line area add an <b>extra line</b> just for the superscript, considering it as normal text (with edge cases, it is preferred to add an extra line)</td>
                                        </tr>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/fivespaces_6-1.jpg" class="table-img" alt="Billy Budd, Ch. 6, pg. 173"></th>
                                            <td class="table-txt">With more than one superscript text, <b>spaced out</b> across the length of the main line, if there are <b>no interruptions</b>, consider the superscript words as part of the <b>same extra line</b> and add <b>5 blank spaces</b> between them</td>
                                        </tr>
                                        <tr>
                                            <th scope="row"><img src="assets/examples/nospaces_3-3.jpg" class="table-img" alt="Billy Budd, Ch. 3, pg. 121"></th>
                                            <td class="table-txt">With more than one superscript text, spaced out across the length of the main line, if there are <b>interruptions</b> (e.g. another superscript word is included in the main line area), add <b>different extra lines</b> for each superscript word</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                            <p class="text-minor"><span class="material-symbols-outlined icon-align" id="zoom_in">zoom_in</span>Click on the pictures to zoom in!</p>
                            <p>We have also put in place our own decisions when it came to <b>underlined text passages</b> (which we have ignored) and <b>additions</b> (<u>see</u>: Annotation Model section). 
                            </p>
                        <h4>Evaluation of results</h4>
                        <p>First, each of us processed 10 leaves of the Billy Budd's manuscript on Transkribus, doing both the layout parsing and the transcription. Then, we swapped the datasets and checked whether we agreed with the decision of the other annotator or not. In case of disagreement, we have discussed and changed our annotating and transcription parameters accordingly. This was also our <b>first pilot campaign</b>, whose results are described further on.</p>
                    </div>
                    <div class="col-lg-8" id="pilot">
                        <h3>Pilot</h3>
                        <p class="minor">We performed, overall, three different pilot campaigns:
                            <ol>
                                <li>The <b>first</b> one, on 20 leaves of the manuscript (specifically, the leaves 1-10 of the first and second chapters), led to the following adjustments:
                                    <ul>
                                        <li>How to handle <b>superscript</b> and <b>strikethrough</b> text passages</li>
                                        <li>How to handle <b>text not transcribed by MEL's experts</b>: we do not include it in the text region and avoid transcribing it ourselves</li>
                                        <li>Keep the different <b>dashes</b> as in the MEL's transcriptions in order to avoid confusion between composed words (short dash: -) and other occurrences (long dash: —)</li>
                                    </ul>
                                </li>
                                <li>The <b>second pilot</b> was carried out on 20 other leaves of the manuscript (11-20 of the first chapter, 11-14 of the second and 1-6 of the fourth chapter) and allowed us to better define how to handle <b>multiple spaced out superscript</b> text passages
                                </li>
                                <li>The <b>third</b> and final <b>pilot</b> was carried out randomly during the first moments of the final annotation campaign: each of us selected random leaves annotated by the other and eventually discussed different decisions, further refining the annotation model</li>
                            </ol>
                        </p>
                    </div>
                    <div class="col-lg-8" id="campaign">
                        <h3>Campaign</h3>
                        <h4>Corpus Annotation</h4>
                        <p>Once the two annotators reached an agreement on how to follow the guidelines derived from the previous pilots, the proper annotation campaign finally began, with the annotation of the remainder of the selected corpus. Chapters from 1 to 16 of Melville's "Billy Budd" and the last 7 pages of "Rip Van Winkle's Lilac" containing the homonymous poem were fully annotated, using the <b>online software Transkribus Lite</b> and reaching a total of <b>175 pages</b> and more than <b>17000 words</b>.</p>
                        <h4>Training the models</h4>
                        <p>The annotated data were then used to train two recognition-models on the same software:</p>
                        <ul>
                            <li><b><i>Melville Handwriting</i></b> was trained having as traning set the whole 16 chapters from "Billy Budd" and as validation set the pages from "Rip Van Winkle's Lilac"</li>
                            <li><b><i>Melville Handwriting Base Model</i></b> trained and validated on the same sets, but with the addition of an <b>"English Handwriting" model</b> provided by Transkribus to refine the recognition process</li>
                        </ul>
                            
                        <p>Both models were trained relying on the <b>PyLaia HTR engine</b> supported by Transkribus and the paramethers were defined according to Transkribus guidelines: <a href="https://readcoop.eu/transkribus/howto/how-to-train-a-handwritten-text-recognition-model-in-transkribus/">"How To Train and Apply Handwritten Text Recognition Models in Transkribus"</a>.<br>For both models we sticked to a default <b>early stopping of 50 epochs</b> and a <b>learning rate of 0,0001%</b>, with the only difference being that, for <b><i>Melville Handwriting Base Model</i></b>, the total <b>number of epochs was lowered</b> from 250 to 150 to avoid overfitting.<p> 
                        
                        <div class="table-responsive-lg">
                            <table class="table">
                                <thead>
                                    <tr>
                                        <th scope="col"></th>
                                        <th scope="col"></th>
                                        <th scope="col">Melville Handwriting</th>
                                        <th scope="col">Melville Handwriting w/ Base Model</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <th scope="row" rowspan="3">Paramethers</th>
                                        <th scope="row">Number of Epochs</th>
                                        <td class="table-txt">250</td>
                                        <td class="table-txt">150</td>
                                    </tr>
                                    <tr>
                                        <th scope="row">Early Stopping</th>
                                        <td class="table-txt">50</td>
                                        <td class="table-txt">50</td>
                                    </tr>
                                    <tr>
                                        <th scope="row">Learning Rate</th>
                                        <td class="table-txt">0,0001</td>
                                        <td class="table-txt">0,0001</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>        
                        <p>The <b>accuracy</b> of the resulting two models can be compared by analysing their Learning Curves (shown in the graphs below) indicating the variation of the <b>Character Error Rate</b> (i.e. the percentage of characters that have been transcribed incorrectly by the Text Recognition model) for number of epochs.</p>
                        <div class="img-comp-container">
                            <div class="img-comp-img">
                              <img src="assets/training/MelvilleHandwriting3.1_Graph.jpg" height="290">
                            </div>
                            <div class="img-comp-img img-comp-overlay">
                              <img src="assets/training/MelvilleHandwritingBased.jpg" height="290">
                            </div>
                        </div>
                        <p style="padding-top: 20px">In the graphs the <b>blue line</b> represents the progress made by the model <b>on the the training set</b>, whereas the <b>red</b> one represents the progress of evaluations <b>on the validation set</b>, on which the program tests itself after the training.<br> 
                            The trend and final value of the <b>CER on the validation set</b> is of course the most significant as it shows how the model is capable of <b>generalising</b>, performing on pages that it has not been trained on.</p>
                        <p>The results of <i>Melville Handwriting Base Model</i> are slightly better performative than the one of the other model, as a CER of 10% or below can be seen as very efficient for automated transcription; however even <i>Melville Handwriting</i> staying with a CER lower than 20% is more than sufficient to work with and could definitely be improved with further work.<p>
                            <div class="table-responsive-lg">
                                <table class="table">
                                    <thead>
                                        <tr>
                                            <th scope="col"></th>
                                            <th scope="col"></th>
                                            <th scope="col">Melville Handwriting</th>
                                            <th scope="col">Melville Handwriting w/ Base Model</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <th scope="row" rowspan="3">Results</th>
                                            <th scope="row">CER on Train Set</th>
                                            <td class="table-txt">13,11%</td>
                                            <td class="table-txt">9,00%</td>
                                        </tr>
                                        <tr>
                                            <th scope="row">CER on Validation Set</th>
                                            <td class="table-txt">15,30%</td>
                                            <td class="table-txt">8,80%</td>
                                        </tr>
                                        <tr>
                                            <th scope="row">Best WER</th>
                                            <td class="table-txt">46,7%</td>
                                            <td class="table-txt">28,1%</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        <br>
                        <h4>Critical Issues</h4>
                        <p>Comparing the transcriptions made on the validation set by the annotators and by the trained models, some criticalities emerged and are worth being highlightened.<br>As shown in the comparison below (annotators' transcription -green- and trained model without base model -red-) on the first page of "Rip Van Winkle's Lilac" it is clear that despite being correctly tagged during the annotation campaign, <b>neither strikethroughs nor superscripts have been correctly recognized</b> by the model during the training.</p>
                        <div class="img-comp-container" style="height: 225px">
                            <div class="img-comp-img">
                              <img src="assets/training/CompareFalse.jpg" height="200">
                            </div>
                            <div class="img-comp-img img-comp-overlay">
                              <img src="assets/training/CompareTrue.jpg" height="200">
                            </div>
                        </div>
                        <h4>Further work</h4>
                        <p>Certainly, this is only the beginning of what could be a much more extent campaign on Melville's original manuscripts. The limited dimensions of our team and, consequently, of the corpus we annotated, definitely prevented us from tackling more in-depth research on the topic. Some improvements could certainly be made by <b>expanding the training corpus</b> and by <b>using HQ images</b> (we could only take screenshots from MEL's website, as there is no download tool made available).<br>However, we are fairly convinced that this project could stand as an inspiring push towards authorial annotation campaigns by means of AI and ML systems.</p>
                    </div>
                    <div class="col-lg-8" id="pubUse">
                        <h3>Publication and use</h3>
                        <p class="minor">In designing our annotation campaign, we have tried to apply the <a href="https://www.go-fair.org/fair-principles/"><b>FAIR principles</b></a> for data publication, making the results of our research findable, accessible, interoperable and reusable.</p>
                        <p><a href="assets/ComputingMelvilleReport.pdf" download><span class="material-symbols-outlined icon-align">file_download</span></a>In addition to the documentation provided in this website, you can freely download the full report about this transcription and annotation campaign.</p>
                    </div>
                </div>
            </div>
        </section>

        <div id="myModal" class="modal">
            <span class="close">&times;</span>
            <img class="modal-content" id="img01">
            <div id="caption"></div>
        </div>

        <img src="assets/sailing_ship.png" id="ship" class="image fitting relative-sh">

        <section class="testimonials text-center" id="team">
            <div class="container px-4">
                <h2 class="mb-5">The team</h2>
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-4">
                        <div class="testimonial-item mx-auto mb-5 mb-lg-0">
                            <img class="img-fluid rounded-circle mb-3" src="assets/team/stakanovina1.jpg" alt="..." />
                            <h5>Federica Bonifazi</h5>
                            <p>
                                <a href="https://www.linkedin.com/in/federica-bonifazi-5b16a6243/"><i class="bi bi-linkedin"></i></a>
                                <a href="mailto: federica.bonifazi@studio.unibo.it"><i class="bi bi-envelope"></i></a>

                            </p>
                        </div>
                    </div>
                    <div class="col-lg-4">
                        <div class="testimonial-item mx-auto mb-5 mb-lg-0">
                            <img class="img-fluid rounded-circle mb-3" src="assets/team/stakanovina2.jpg" alt="..." />
                            <h5>Orsola Maria Borrini</h5>
                            <p style="vertical-align: middle;">
                                <a href="https://www.linkedin.com/in/orsola-maria-borrini-362142253/"><i class="bi bi-linkedin"></i></a>
                                <a href="mailto: orsolamaria.borrini@studio.unibo.it"><i class="bi bi-envelope"></i></a>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Footer-->
        <footer class="py-5 bg-dark">
            <div class="container px-4">
                <p class="m-0 text-center text-white">Copyright &copy; Computing Melville 2022 <br>
                    <img src="assets/herman-melville-sig.svg" alt="Hermann Melville svg signature" class="invertsignature"><br>
                    Computing Melville is a project developed for the <a href="https://www.unibo.it/en/teaching/course-unit-catalogue/course-unit/2022/424786" class="footer-a">"Semantic Digital Libraries"</a> course (a.a. 2022/2023) <br>
                    within the <a href="https://corsi.unibo.it/2cycle/DigitalHumanitiesKnowledge" class="footer-a">Digital Humanities and Digital Knowledge Master's Degree</a>
                    at <a href="https://www.unibo.it/en/homepage" class="footer-a">Alma Mater Studiorum - University of Bologna</a><br>
                    <a href="https://creativecommons.org/licenses/by-nc/4.0/">
                        <img src="assets/creativecommons.jpg" alt="Licence Creative Commons 4.0"
                            style="height:40px;margin:1rem;"></a>
                    <a href="https://github.com/OrsolaMBorrini/ComputingMelville.git">
                        <svg xmlns="http://www.w3.org/2000/svg" width="60" height="60" fill="white" class="bi bi-github"
                            viewBox="0 -3 30 30">
                            <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                        </svg>
                    </a>
                </p>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
        <script>
            /*Execute a function that will execute an image compare function for each element with the img-comp-overlay class:*/
            initComparisons();
        </script>
        <script>
        // create references to the modal...
        var modal = document.getElementById('myModal');
        // to all images -- note I'm using a class!
        var images = document.getElementsByClassName('table-img');
        // the image in the modal
        var modalImg = document.getElementById("img01");
        // and the caption in the modal
        var captionText = document.getElementById("caption");
        
        // Go through all of the images with our custom class
        for (var i = 0; i < images.length; i++) {
          var img = images[i];
          // and attach our click listener for this image.
          img.onclick = function(evt) {
            console.log(evt);
            modal.style.display = "block";
            modalImg.src = this.src;
            captionText.innerHTML = this.alt;
          }
        }

        var span = document.getElementsByClassName("close")[0];
        
        span.onclick = function() {
          modal.style.display = "none";
        }
    </script>        
    </body>
</html>
